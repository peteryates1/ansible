---
- name: Load SSH authorized keys
  set_fact:
    ssh_authorized_keys: "{{ lookup('file', ssh_authorized_keys_file).split('\n') | select('match', '^(?!#)(?!$)') | list }}"

- name: Ensure base image directory exists
  file:
    path: "{{ base_image_dir }}"
    state: directory
    mode: '0755'

# Template detection
- name: Set template paths
  set_fact:
    template_dir: "{{ base_image_dir }}/templates"
    template_path: "{{ base_image_dir }}/templates/{{ vm_type }}-base.qcow2"

- name: Adjust template path for common type
  set_fact:
    template_path: "{{ base_image_dir }}/templates/common-hardened.qcow2"
  when: vm_type == 'common'

- name: Check if template exists
  stat:
    path: "{{ template_path }}"
  register: template_stat

- name: Fail if required template is missing
  fail:
    msg: >-
      Required template not found: {{ template_path }}.
      Create templates first:
      ./vm template create common
      and then ./vm template create {{ vm_type }} (unless vm_type is common).
  when: not template_stat.stat.exists

- name: Display template in use
  debug:
    msg: "Using template: {{ template_path }}"

- name: Create VM directory
  file:
    path: "{{ base_image_dir }}/{{ vm_name }}"
    state: directory
    owner: "{{ vm_user }}"
    group: "{{ vm_user }}"
    mode: '0755'

- name: Check if VM disk exists
  stat:
    path: "{{ base_image_dir }}/{{ vm_name }}/{{ vm_name }}.qcow2"
  register: vm_disk_stat

# Create disk from template
- name: Create VM disk from template
  command: >
    qemu-img create -f qcow2 -F qcow2
    -b {{ template_path }}
    {{ base_image_dir }}/{{ vm_name }}/{{ vm_name }}.qcow2
    {{ vm_disk_size }}
  args:
    chdir: "{{ base_image_dir }}/{{ vm_name }}"
  when: not vm_disk_stat.stat.exists

- name: Set VM disk ownership
  file:
    path: "{{ base_image_dir }}/{{ vm_name }}/{{ vm_name }}.qcow2"
    owner: "{{ vm_user }}"
    group: "{{ vm_user }}"

- name: Generate cloud-init user-data (instance from template)
  template:
    src: instance-user-data.yml.j2
    dest: "{{ base_image_dir }}/{{ vm_name }}/user-data"
    owner: "{{ vm_user }}"
    group: "{{ vm_user }}"
    mode: '0644'
  register: user_data_render

- name: Generate cloud-init meta-data
  template:
    src: meta-data.yml.j2
    dest: "{{ base_image_dir }}/{{ vm_name }}/meta-data"
    owner: "{{ vm_user }}"
    group: "{{ vm_user }}"
    mode: '0644'
  register: meta_data_render

- name: Generate cloud-init network-config
  template:
    src: network-config.yml.j2
    dest: "{{ base_image_dir }}/{{ vm_name }}/network-config"
    owner: "{{ vm_user }}"
    group: "{{ vm_user }}"
    mode: '0644'
  register: network_config_render

- name: Check if cloud-init ISO exists
  stat:
    path: "{{ base_image_dir }}/{{ vm_name }}/cloud-init.iso"
  register: cloud_init_iso_stat

- name: Generate cloud-init ISO
  command: >
    genisoimage -output cloud-init.iso -volid cidata -joliet -rock
    user-data meta-data network-config
  args:
    chdir: "{{ base_image_dir }}/{{ vm_name }}"
  when: >
    user_data_render.changed or
    meta_data_render.changed or
    network_config_render.changed or
    not cloud_init_iso_stat.stat.exists

- name: Set cloud-init ISO ownership
  file:
    path: "{{ base_image_dir }}/{{ vm_name }}/cloud-init.iso"
    owner: "{{ vm_user }}"
    group: "{{ vm_user }}"

- name: Check if VM exists
  command: virsh list --all --name
  register: vm_list
  changed_when: false

- name: Create VM with virt-install
  command: >
    virt-install
    --name {{ vm_name }}
    --memory {{ vm_memory }}
    --vcpus {{ vm_vcpus }}
    --disk {{ base_image_dir }}/{{ vm_name }}/{{ vm_name }}.qcow2,device=disk,bus=virtio
    --disk {{ base_image_dir }}/{{ vm_name }}/cloud-init.iso,device=cdrom
    --os-variant debian11
    --virt-type kvm
    --network network=default
    --serial file,path={{ base_image_dir }}/{{ vm_name }}/console.log
    --console pty,target_type=serial
    --import
    --noautoconsole
  when: vm_name not in vm_list.stdout_lines
  register: vm_created

- name: Check if existing VM is running
  command: virsh list --state-running --name
  register: running_vms
  changed_when: false
  when: vm_name in vm_list.stdout_lines

- name: Start existing VM if not running
  command: virsh start {{ vm_name | quote }}
  when: vm_name in vm_list.stdout_lines and vm_name not in running_vms.stdout_lines
  register: vm_started

- name: Wait for VM to boot
  pause:
    seconds: 15
  when: (vm_created is changed) or (vm_started is changed)

- name: Get VM IP address
  shell: virsh domifaddr {{ vm_name | quote }} | grep -oP '(\d+\.){3}\d+' | head -1
  register: vm_ip
  changed_when: false
  retries: 10
  delay: 5
  until: vm_ip.stdout != ""

- name: Get VM MAC address
  shell: virsh domiflist {{ vm_name | quote }} | awk 'NR > 2 && $5 ~ /^([0-9A-Fa-f]{2}:){5}[0-9A-Fa-f]{2}$/ { print $5; exit }'
  register: vm_mac
  changed_when: false

- name: Add static DHCP reservation for VM
  shell: |
    set -euo pipefail
    mac="{{ vm_mac.stdout }}"
    ip="{{ vm_ip.stdout }}"

    # Check if reservation already exists for this MAC
    existing="$(virsh net-dumpxml default | grep -i "$mac" || true)"
    if [ -n "$existing" ]; then
      echo "already_reserved"
      exit 0
    fi

    virsh net-update default add ip-dhcp-host \
      "<host mac='${mac}' name='{{ vm_name }}' ip='${ip}'/>" \
      --live --config
    echo "reserved:${mac}:${ip}"
  args:
    executable: /bin/bash
  register: dhcp_reservation
  changed_when: "'reserved:' in dhcp_reservation.stdout"

- name: Display VM information
  debug:
    msg: |
      VM {{ vm_name }} is ready!
      Type: {{ vm_type }}
      IP: {{ vm_ip.stdout }}
      SSH: ssh peter@{{ vm_ip.stdout }}
